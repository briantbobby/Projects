{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGRD 2700 Class Project\n",
    "\n",
    "*   Using the Stanford Open Policing Project to reveal racial bias in policing\n",
    "*   Author: Brian Bobby (btb68)\n",
    "\n",
    "The Stanford Open Policing Project describes its mission as \"collecting and standardizing data on vehicle and pedestrian stops from law enforcement departments across the country... and making that information freely available,\" (www.openpolicing.stanford.edu). As no such dataset readily exists on a national level, the Stanford Open Policing Project is filling a crucial void in the path to open and public analysis of our police forces in a time when racial biases are increasingly being brought to light and such analysis is critically important.\n",
    "\n",
    "For my class project, I thought that an interesting and telling way to discover racial biases in policing would be to see if I could create a simple machine learning model that could, given information about any traffic stop, accurately predict the race of the citizen involved. If I succeed in that, can I possibly predict other attributes of the citizen involved? Gender? Age? Does my ability to make these predictions accurately change depending on what location the data comes from?\n",
    "\n",
    "To start, I will simply choose the city that seems to have the most available and most complete dataset, which seems to be Nashville, Tennessee. The dataset for Nashville has 70% or more responses in all of the fields that the Stanford Open Policing Project categorizes data into (it seems to be the only city with this distinction), and has more than 3 millions rows of data (a relatively large amount compared to the rest of the datasets):\n",
    "![title](ssfromwebsite.png)\n",
    "\n",
    "<br>\n",
    "(a box indicates 70% or more response rate in that column)\n",
    "\n",
    "For these reasons, I will begin my modelling using the Nashville dataset, and if need be, will switch to another good candidate. I will first import the dataset, and then remove columns that are unecessary for my project. There are 42 columns, and I will be removing the following: location, lat, lng, reporting_area, zone (these five can all be more usefully generalized with the column \"precinct\", which I will be keeping), officer_id, officer_id_hash (it will be too tedious to analyze on an officer-by-officer basis), all the uncleaned, raw columns of data included as the last few columns, as these have all been recategorized into more useful columns by the Stanford Open Policing Project, and a few other columns I just don't need. Additionally, I will be removing all rows that have nonresponses in order to have complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,8,15,16,17,22,23,24,25,29,30,31,32,33,35,36,37,38,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining before removing rows with missing values: 3092351\n",
      "Rows remaining after removing rows with missing values: 111364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import downloaded csv file as pandas dataframe\n",
    "nashville_df = pd.read_csv('tn_nashville_2020_04_01.csv')\n",
    "\n",
    "# drop unnecessary columns\n",
    "nashville_df.drop(['raw_row_number','location','lat','lng','reporting_area',\n",
    "                   'zone','officer_id_hash','type','reason_for_stop',\n",
    "                   'vehicle_registration_state','notes','raw_verbal_warning_issued',\n",
    "                   'raw_written_warning_issued','raw_traffic_citation_issued',\n",
    "                   'raw_misd_state_citation_issued','raw_suspect_ethnicity',\n",
    "                   'raw_driver_searched','raw_passenger_searched','raw_search_consent',\n",
    "                   'raw_search_arrest','raw_search_warrant','raw_search_inventory',\n",
    "                   'raw_search_plain_view'],axis=1,inplace=True)\n",
    "\n",
    "print('Rows remaining before removing rows with missing values:',\n",
    "      len(nashville_df))\n",
    "\n",
    "# drop rows that have missing values\n",
    "print('Rows remaining after removing rows with missing values:',\n",
    "      len(nashville_df.dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, one or more columns have a lot of nonresponses, and I'd rather have much more data to work with. I will attempt to see which column is this incomplete, and remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                        0\n",
       "time                     5467\n",
       "precinct               390222\n",
       "subject_age               839\n",
       "subject_race             1850\n",
       "subject_sex             12822\n",
       "violation                8020\n",
       "arrest_made                28\n",
       "citation_issued           320\n",
       "warning_issued            337\n",
       "outcome                  1935\n",
       "contraband_found      2964646\n",
       "contraband_drugs      2964646\n",
       "contraband_weapons    2964646\n",
       "frisk_performed            22\n",
       "search_conducted           39\n",
       "search_person              43\n",
       "search_vehicle             41\n",
       "search_basis          2964646\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nashville_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the contraband columns and search column all have a lot of nonresponses, so I will remove them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining after removing rows with missing values: 2647717\n"
     ]
    }
   ],
   "source": [
    "# drop columns\n",
    "nashville_df.drop(['contraband_found','contraband_drugs','contraband_weapons',\n",
    "                   'search_basis'],axis=1,inplace=True)\n",
    "\n",
    "# drop rows with nonresponses\n",
    "nashville_df.dropna(inplace=True)\n",
    "\n",
    "# drop rows where 'precinct'='U', as these also signify unknown data\n",
    "nashville_df.drop(nashville_df[nashville_df['precinct']=='U'].index.tolist(),\n",
    "                  inplace=True)\n",
    "\n",
    "# drop rows where the subject race is listed as \"unknown\"\n",
    "nashville_df.drop(nashville_df[nashville_df['subject_race']=='unknown']\n",
    "                  .index.tolist(),inplace=True)\n",
    "\n",
    "# reset index\n",
    "nashville_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print('Rows remaining after removing rows with missing values:',\n",
    "      len(nashville_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have over 2.5 million complete rows of data, each representing a single traffic stop. My dataframe now looks somthing like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>precinct</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>violation</th>\n",
       "      <th>arrest_made</th>\n",
       "      <th>citation_issued</th>\n",
       "      <th>warning_issued</th>\n",
       "      <th>outcome</th>\n",
       "      <th>frisk_performed</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_person</th>\n",
       "      <th>search_vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>moving traffic violation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>citation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>vehicle equipment violation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>warning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>registration</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>warning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>moving traffic violation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>warning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:04:00</td>\n",
       "      <td>7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>seatbelt violation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>warning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time precinct  subject_age subject_race subject_sex  \\\n",
       "0  2010-10-10  10:00:00        5         18.0        white        male   \n",
       "1  2010-10-10  10:00:00        1         52.0        white        male   \n",
       "2  2010-10-10  22:00:00        3         25.0        white        male   \n",
       "3  2010-10-10  01:00:00        7         26.0        white      female   \n",
       "4  2010-10-10  10:04:00        7         33.0        white        male   \n",
       "\n",
       "                     violation arrest_made citation_issued warning_issued  \\\n",
       "0     moving traffic violation       False            True          False   \n",
       "1  vehicle equipment violation       False           False           True   \n",
       "2                 registration       False           False           True   \n",
       "3     moving traffic violation       False           False           True   \n",
       "4           seatbelt violation       False           False           True   \n",
       "\n",
       "    outcome frisk_performed search_conducted search_person search_vehicle  \n",
       "0  citation           False            False         False          False  \n",
       "1   warning           False            False         False          False  \n",
       "2   warning           False            False         False          False  \n",
       "3   warning           False            False         False          False  \n",
       "4   warning           False            False         False          False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nashville_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will turn all of my categorical features into numerical ones using One Hot Encoding. This strategy breaks up a column such as \"violation\" into a bunch of different columns, each signifying one speicifc violation, such as \"moving traffic violation\", \"vehicle equipment violation\", or \"registration\", and assigns a 1 to that row in that column if the original violation matches that new column, or a 0 if the original violation does not match that column. I will be employing this startegy on columns \"subject_sex\", \"violation\", and \"outcome\". I will turn all the columns containing booleans into numerical columns simply by replacing each \"True\" with a 1, and each \"False\" with a 0. After this, all of my columns should be numerical besides my target column, \"subject_race\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert boolean columns to numerical\n",
    "nashville_df['arrest_made']=nashville_df['arrest_made'].astype(int)\n",
    "nashville_df['citation_issued']=nashville_df['citation_issued'].astype(int)\n",
    "nashville_df['warning_issued']=nashville_df['warning_issued'].astype(int)\n",
    "nashville_df['frisk_performed']=nashville_df['frisk_performed'].astype(int)\n",
    "nashville_df['search_conducted']=nashville_df['search_conducted'].astype(int)\n",
    "nashville_df['search_person']=nashville_df['search_person'].astype(int)\n",
    "nashville_df['search_vehicle']=nashville_df['search_vehicle'].astype(int)\n",
    "\n",
    "\n",
    "# convert categorical columns into numerical using One Hot Encoding\n",
    "\n",
    "nashville_df['subject_sex']=pd.Categorical(nashville_df['subject_sex'])\n",
    "dfDummies=pd.get_dummies(nashville_df['subject_sex'],prefix='subject_sex')\n",
    "nashville_df.insert(6,'subject_sex_male',dfDummies['subject_sex_male'],)\n",
    "nashville_df.insert(7,'subject_sex_female',dfDummies['subject_sex_female'],)\n",
    "nashville_df.drop('subject_sex',axis=1,inplace=True)\n",
    "\n",
    "nashville_df['violation']=pd.Categorical(nashville_df['violation'])\n",
    "dfDummies=pd.get_dummies(nashville_df['violation'],prefix='violation')\n",
    "nashville_df.insert(8,'violation_child_restraint',\n",
    "                    dfDummies['violation_child restraint'],)\n",
    "nashville_df.insert(9,'violation_investigative_stop',\n",
    "                    dfDummies['violation_investigative stop'],)\n",
    "nashville_df.insert(10,'violation_moving_traffic_violation',\n",
    "                    dfDummies['violation_moving traffic violation'],)\n",
    "nashville_df.insert(11,'violation_parking_violation',\n",
    "                    dfDummies['violation_parking violation'],)\n",
    "nashville_df.insert(12,'violation_registration',\n",
    "                    dfDummies['violation_registration'],)\n",
    "nashville_df.insert(13,'violation_safety_violation',\n",
    "                    dfDummies['violation_safety violation'],)\n",
    "nashville_df.insert(14,'violation_seatbelt_violation',\n",
    "                    dfDummies['violation_seatbelt violation'],)\n",
    "nashville_df.insert(15,'violation_vehicle_equipment_violation',\n",
    "                    dfDummies['violation_vehicle equipment violation'],)\n",
    "nashville_df.drop('violation',axis=1,inplace=True)\n",
    "\n",
    "nashville_df['outcome']=pd.Categorical(nashville_df['outcome'])\n",
    "dfDummies=pd.get_dummies(nashville_df['outcome'],prefix='outcome')\n",
    "nashville_df.insert(19,'outcome_arrest',dfDummies['outcome_arrest'],)\n",
    "nashville_df.insert(20,'outcome_citation',dfDummies['outcome_citation'],)\n",
    "nashville_df.insert(21,'outcome_warning',dfDummies['outcome_warning'],)\n",
    "nashville_df.drop('outcome',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have all numerical columns besides my target, \"subject_race\". The column \"subject_sex\" was replaced by two columns, one for \"male\" and one for \"female\". The \"violation column was replaced by eight separate columns, one for each type of violation. The \"outcome\" column was separated into three columns for \"arrest\", \"citation\", and \"warning\". My dataframe now looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>precinct</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex_male</th>\n",
       "      <th>subject_sex_female</th>\n",
       "      <th>violation_child_restraint</th>\n",
       "      <th>violation_investigative_stop</th>\n",
       "      <th>violation_moving_traffic_violation</th>\n",
       "      <th>...</th>\n",
       "      <th>arrest_made</th>\n",
       "      <th>citation_issued</th>\n",
       "      <th>warning_issued</th>\n",
       "      <th>outcome_arrest</th>\n",
       "      <th>outcome_citation</th>\n",
       "      <th>outcome_warning</th>\n",
       "      <th>frisk_performed</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_person</th>\n",
       "      <th>search_vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>10:04:00</td>\n",
       "      <td>7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time precinct  subject_age subject_race  subject_sex_male  \\\n",
       "0  2010-10-10  10:00:00        5         18.0        white                 1   \n",
       "1  2010-10-10  10:00:00        1         52.0        white                 1   \n",
       "2  2010-10-10  22:00:00        3         25.0        white                 1   \n",
       "3  2010-10-10  01:00:00        7         26.0        white                 0   \n",
       "4  2010-10-10  10:04:00        7         33.0        white                 1   \n",
       "\n",
       "   subject_sex_female  violation_child_restraint  \\\n",
       "0                   0                          0   \n",
       "1                   0                          0   \n",
       "2                   0                          0   \n",
       "3                   1                          0   \n",
       "4                   0                          0   \n",
       "\n",
       "   violation_investigative_stop  violation_moving_traffic_violation  \\\n",
       "0                             0                                   1   \n",
       "1                             0                                   0   \n",
       "2                             0                                   0   \n",
       "3                             0                                   1   \n",
       "4                             0                                   0   \n",
       "\n",
       "        ...        arrest_made  citation_issued  warning_issued  \\\n",
       "0       ...                  0                1               0   \n",
       "1       ...                  0                0               1   \n",
       "2       ...                  0                0               1   \n",
       "3       ...                  0                0               1   \n",
       "4       ...                  0                0               1   \n",
       "\n",
       "   outcome_arrest  outcome_citation  outcome_warning  frisk_performed  \\\n",
       "0               0                 1                0                0   \n",
       "1               0                 0                1                0   \n",
       "2               0                 0                1                0   \n",
       "3               0                 0                1                0   \n",
       "4               0                 0                1                0   \n",
       "\n",
       "   search_conducted  search_person  search_vehicle  \n",
       "0                 0              0               0  \n",
       "1                 0              0               0  \n",
       "2                 0              0               0  \n",
       "3                 0              0               0  \n",
       "4                 0              0               0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nashville_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I am also going to reduce the number of \"race\" categories to just two: \"white\" and \"person of color\". I made this decision mainly to give my model an easier time predicting race — it is a fact that all people of color in this country experience discrimination, and I think it is more realistic to ask my model to discern between prejudice and no prejudice on a basis of race than to ask it to discern between slightly differing levels of prejudice, whatever those may be. For this reason, my model will have to predict whether the subject is white or a person of color, and the accuracy of such predictions should still be extremely telling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# categorize \"subject_race\" in \"white\" and \"poc\"\n",
    "nashville_df['subject_race'][nashville_df['subject_race']!='white']='poc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to try a model and see how successful it is. As a side note, I will not be including the columns \"date\" or \"time\" in my first model. However, that could be an interesting addition in a later model. I will be implementing a Naive Bayes' model, mostly because it's name reminded me of this class and I wanted to look into how it related to the Bayes' Theorem we learned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Wikipedia, the algorithm stems directly from the simple theorem we learned in class that calculates conditional probabilities. The classifier algorithm simply expands the theorem to take in multiple features as the condition, and then chooses the outcome with the highest likelihood for each prediction. Interestingly enough, the specific classifier that I will use, called a Gaussian Naive Bayes' classifier, uses the normal distribution to approximate each numerical feature, making calculations of conditional probabilities much more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes' model training accuracy score: 0.5583774318717121\n",
      "Naive Bayes' model testing accuracy score: 0.5588241959119544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# establish features and target parameter\n",
    "X = nashville_df.drop(['date','time','subject_race'], axis=1)\n",
    "Y = nashville_df['subject_race']\n",
    "\n",
    "# split data into a traning set (80% of the data) and a testing set\n",
    "# (20% of the data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = .2,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# create the model\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Naive Bayes' model training accuracy score:\",\n",
    "      model.score(x_train,y_train))\n",
    "print(\"Naive Bayes' model testing accuracy score:\",\n",
    "      model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the model was able to accurately predict 56% of the data that it trained on, which was 80% of the original dataset. Additionally, when faced with entirely new data that it had not encountered before, the training set consisting of the other 20% of the original dataset, it again scored an accuracy of 56%. This means the model was not overfitted to the training data, and our random split yielded consistent results in both sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While astounding, as I will discuss later, I believe these results could be improved slightly. To do so, I will try a few other models, and compare their accuracies. The next model I will try is a Decision Tree Classifier, and to enhance it I will iterate through maximum depths to assign to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model training accuracy score:  0.6385984922877042\n",
      "Decision Tree model testing accuracy score:  0.6412861461268744\n",
      "depth =  13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# establish features and target parameter\n",
    "X = nashville_df.drop(['date','time','subject_race'], axis=1)\n",
    "Y = nashville_df['subject_race']\n",
    "\n",
    "# split data into a traning set (80% of the data) and a testing set\n",
    "# (20% of the data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = .2,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# create the model, iterating through various depths\n",
    "max_score=0\n",
    "training_score=0\n",
    "max_score_depth=0\n",
    "for i in range(1,15):\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    model.fit(x_train,y_train)\n",
    "    score=model.score(x_test,y_test)\n",
    "    trscore=model.score(x_train,y_train)\n",
    "    if(score>max_score):\n",
    "        max_score=score\n",
    "        training_score=trscore\n",
    "        max_score_depth=i\n",
    "\n",
    "print('Decision Tree model training accuracy score: ',max_score)\n",
    "print('Decision Tree model testing accuracy score: ',training_score)\n",
    "print('depth = ',max_score_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the model was able to accurately predict 64% of the data that it trained on, which was 80% of the original dataset. Additionally, when faced with entirely new data that it had not encountered before, the training set consisting of the other 20% of the original dataset, it again scored an accuracy of 64%. This means the model was not overfitted to the training data, and our random split yielded consistent results in both sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two choices, the first model predicts correctly almost 56% of the time. Given the same two choices, the second model predicts correctly 64% of the time. This result is significantly higher than naive random guessing, especially considering that the model achieved this success rate over 2.5 million independent trials. If police interactions truly had no pattern to them, the strategy should be just that: random guessing! If there really was no difference between traffic stops whose subjects are different races, then no model, no matter how complex, would be able to accurately discern between them, as there would be no difference to discern. But this model can accurately predict 64% of occurences, and it was shockingly easy for me to make. There is an obvious pattern, because if there wasn't, I wouldn't be able to make accurate predictions about a subject's race! I only wonder what an expert in machine learning could discover further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this model can accurately predict the race of the subject in 64% of traffic stops given solely situational information about the stop. Let that sink in for a moment. Race should be playing no role in the event of a police interaction, and instead, it's playing enough of a role that significant, *measurable* patterns are being picked up in the data on an incredibly large scale - the scale of an entire large American city, over the course of over 2.5 million traffic stops over a number of years. This speaks volumes as to the current state of our country. Racism reaches so much farther than just the cases that make the news. - it is prevalent at a systematic level, and the data proves it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**Sources**\n",
    "*   https://openpolicing.stanford.edu\n",
    "*   https://en.wikipedia.org/wiki/Naive_Bayes_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
